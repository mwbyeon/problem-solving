
* 알고리즘
1. 트레이닝 : 단어 빈도를 저장한 사전 데이터 파일을 생성
	1) train.txt에서 단어에 불필요한 특수문자 제거하고 숫자 및 영문만 사용
	2) 복수형 단어를 단수형을 변형후 사전에 추가 ("friends" -> "friend")
	3) 오타에 대응하기 위해 맨앞, 맨뒤 문자를 제거르 사전에 추가 ("abcde" -> "bcde", "abcd")
	4) 두 개의 단어를 합쳐서 사전에 추가 ("a b")
	5) 오타에 대응하기 위해 중간 두 개의 문자를 바꾼 후 사전에 추가 ("signature" -> "singature")
	6) "a", "i" 외의 단어로써 출현 가능성이 낮은 한 글자 단어를 사전에서 제거

2. 테스트 : 사전 데이터 파일을 로드하고 입력 쿼리에 대해 결과를 예측
	1) 트레이닝 단계에서 생성된 단어 사전 파일을 로드
	2) 단어 출현 확률 분포에 기반하여 가장 높은 스코어를 갖는 단어 분리 조합을 생성
		- 단어가 사전에 있을 경우 출현 확률은 "(현재 단어의 출현 빈도) / (전체 단어 출현 빈도의 합)"
		- 단어가 사전에 없을 경우 출현 확률은 단어 길이에 기반 "1 / (전체 단어 출현 빈도의 합) * 10^길이"
		  (단어 길이에 따른 출현 빈도는 실험적으로 "10^길이"가 가장 근접하다고 판단)
		- 입력 쿼리에 대해 모든 분리 가능한 경우를 구한 후, 각 단어별 출현 확률의 합이 가장 높은 조합을 선택
		- 단어 중복 입력에 대해 빠르게 처리하기 위해 결과를 재활용하는 memoization 기법 사용
	3) 2)에서 분리된 단어에 대해 합치는 것이 낫다고 판단 될 경우 단어를 병합 (출현 확률에 기반)
		- 두 개로 분리된 단어를 하나로 합쳤을 때 출현 확률이 더 높다면 합치기
	4) 각 단어에 대해 분리하는 것이 낫다고 판단 될 경우 단어를 분리 (출현 확률에 기반)
		- 한 단어를 두 개로 분리했을 때 출현 빈도가 더 높다면 분리하기


* 코드 : 위의 "알고리즘" 항목에서 같이 설명 


* 실행 환경
	- Mac / Python 2.7에서 테스트 되었습니다.


* 실행 방법 ( ./src 경로로 이동 후 실행 )
	- train : python qseg.py -r train -i ../oth/train.txt -m ../res/model
	- test  : python qseg.py -r test -i ../oth/test.qry -m ../res/model -o ../ans/test.ans.1
	- eval  : python qseg.py -r eval -i ../oth/train.qry -m ../res/model


* 실행 시간 (macbook air 기준)
	- train : 6.7 sec 
	- test  : 4.8 sec


* 참고
	- test.ans.2의 경우 train.qry도 이용하여 학습한 결과입니다. (train함수 참고)
